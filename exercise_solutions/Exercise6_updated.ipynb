{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6b on Advanced segmentation: Fisherman's Linear discriminant analysis for segmentation\n",
    "\n",
    "The exercise is to perform advanced segmentation of two brain tissue types.  To improve the segmentation result over the simpler intensity histogram thresholding methods we \n",
    "will use two input features compared to a single. The two input features are two different image modalities acquired on the same brain. \n",
    "\n",
    "The two tissue types to be segmented are: \n",
    "1. The White Matter (WM) is the tissue type that contain the brain network - like the cables in the internet. The  WM ensure the communication flow between functional brain regions. \n",
    "2. The Grey Matter (GM) is the tissue type that contain the cell bodies at the end of the brain network and are the functional units in the brain. The functional units are like CPUs in the computer. They are processing our sensorial input and are determining a reacting to these. It could be to start running.\n",
    "\n",
    "Provided data:\n",
    "ex6_ImgData2Load.mat contain all image and ROI data which are loaded into the variables:\n",
    "- ImgT1 - One axial slice of brain using T1W MRI acquisition\n",
    "- ImgT2 - One axial slice of brain using T2W MRI acquisition\n",
    "- ROI_WM - Binary training data for class 1: Expert identification of voxels belonging to tissue type: White Matter\n",
    "- ROI_GM - Binary training data for class 2: Expert identification of voxels belonging to tissue type: Grey Matter\n",
    "\n",
    "LDA.py  Python function that realise the Fisher's linear discriminant analyse as described in the lecture notes\n",
    "\n",
    "Exercise -  You simply go step-by-step and fill the command lines and answer/discuss the questions.\n",
    "\n",
    "April 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from skimage.morphology import opening, closing\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from LDA import LDA # You should have LDA.py in the same folder as the current script, otherwise you can just copy the function in the current script. "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "in_dir = 'data/'\n",
    "in_file = 'ex6_ImagData2Load.mat'\n",
    "data = sio.loadmat(in_dir + in_file)\n",
    "ImgT1 = data['ImgT1']\n",
    "ImgT2 = data['ImgT2']\n",
    "ROI_GM = data['ROI_GM'].astype(bool)\n",
    "ROI_WM = data['ROI_WM'].astype(bool)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "mask_init = ImgT1 > 10\n",
    "mask = opening(mask_init, disk(2))\n",
    "mask = closing(mask, disk(3))\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 10))\n",
    "axs[0].imshow(ImgT1, cmap = 'gray')\n",
    "axs[1].imshow(mask_init, cmap = 'gray', interpolation = 'none')\n",
    "axs[2].imshow(mask, cmap = 'gray', interpolation = 'none')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def my_show_1D_histogram(img, mask, img_name, axs):\n",
    "    axs[0].imshow(img, cmap = 'gray')\n",
    "    axs[0].set_title(img_name)\n",
    "    axs[0].set_axis_off()\n",
    "\n",
    "    intensities = img[mask]\n",
    "    axs[1].hist(intensities, bins = 100)\n",
    "    axs[1].set_title(f'1D Histogram {img_name}')\n",
    "    axs[1].set_xlabel('Intensities')\n",
    "    axs[1].set_ylabel('Frequency')\n",
    "\n",
    "    return intensities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize = (15, 8))\n",
    "T1_intensities = my_show_1D_histogram(ImgT1, mask, 'T1w image', axs[0, 0:2])\n",
    "T2_intensities = my_show_1D_histogram(ImgT2, mask, 'T2w image', axs[1, 0:2])\n",
    "axs[0,2].hist2d(T1_intensities, T2_intensities, bins = 100)\n",
    "axs[0,2].set_xlabel('T1w intensities')\n",
    "axs[0,2].set_ylabel('T2w intensities')\n",
    "axs[0,2].set_title('2D histogram')\n",
    "\n",
    "axs[1,2].scatter(T1_intensities, T2_intensities)\n",
    "axs[1,2].set_xlabel('T1w intensities')\n",
    "axs[1,2].set_ylabel('T2w intensities')\n",
    "axs[1,2].set_title('Scatter plot')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: What is the intensity threshold that can separate the GM and WM classes (roughly) from the 1D histograms?\n",
    "\n",
    "A1: For T1:about 500 and for T2: about 160\n",
    "\n",
    "**Q2**: Can the GM and WM intensity classes be observed in the 2D histogram and scatter plot? \n",
    "\n",
    "A2: Yes there appear clear two clusters with maxium intensitised in the 2D histogram that represent the two classes distributions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**: Does the ROI drawings look like what you expect from an expert? \n",
    "\n",
    "A3: No, its just some stribes here and there in the outline the intensities of the two classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "axs.imshow(ImgT1, cmap = 'gray')\n",
    "axs.imshow(ROI_GM, cmap = 'Reds', alpha = 0.5, interpolation = 'none')\n",
    "axs.imshow(ROI_WM, cmap = 'Greens', alpha = 0.5, interpolation = 'none')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**: What is the difference between the 1D histogram of the training examples and the 1D histogram of the whole image? Is the difference expected?  \n",
    "\n",
    "A4: It looks very alike the full image histogram except for better class seperation and there is no background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# This is not necessary with the coding style followed in this solution.\n",
    "qC1 = np.argwhere(ROI_WM) # Shape (399, 2) \n",
    "qC2 = np.argwhere(ROI_GM) # (280, 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "trainWM_T1 = ImgT1[ROI_WM] # trainWM_T1 = ImgT1[qC1[:,0], qC1[:,1]]\n",
    "trainGM_T1 = ImgT1[ROI_GM] # trainGM_T1 = ImgT1[qC2[:,0], qC2[:,1]]\n",
    "\n",
    "trainWM_T2 = ImgT2[ROI_WM] # trainWM_T2 = ImgT2[qC1[:,0], qC1[:,1]]\n",
    "trainGM_T2 = ImgT2[ROI_GM] # trainGM_T2 = ImgT2[qC2[:,0], qC2[:,1]]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 4), sharex = False, sharey = True)\n",
    "axs[0].hist(trainWM_T1, bins=20, color = 'navy', label = 'WM', alpha = 0.8)\n",
    "axs[0].hist(trainGM_T1, bins=20, color = 'orange', label = 'GM', alpha = 0.8)\n",
    "axs[0].set_ylabel('Frequency')\n",
    "axs[0].set_xlabel('Intensities')\n",
    "axs[0].set_title('T1w')\n",
    "\n",
    "axs[1].hist(trainWM_T2, bins=20, color = 'navy', label = 'WM', alpha = 0.8)\n",
    "axs[1].hist(trainGM_T2, bins=20, color = 'orange', label = 'GM', alpha = 0.8)\n",
    "axs[1].set_xlabel('Intensities')\n",
    "axs[1].set_title('T2w')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# Feature matrix, X -> Shape: (n_samples, n_features)\n",
    "X1 = np.c_[ImgT1[ROI_WM], ImgT2[ROI_WM]] \n",
    "X2 = np.c_[ImgT1[ROI_GM], ImgT2[ROI_GM]]\n",
    "X = np.r_[X1, X2]\n",
    "\n",
    "# Label vector, T -> Shape: (n_samples)\n",
    "n_pixels = X.shape[0]\n",
    "n_wm_pixels = X1.shape[0]\n",
    "T = np.zeros((n_pixels, 1))\n",
    "T[n_wm_pixels:] = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "X1.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**: How does the class separation appear in the 2D scatter plot compared with 1D histogram. Is it better?\n",
    "\n",
    "A5: The seperation between the two classes appear to be much better in 2D scatter plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X1[:,0], X1[:,1], c = 'g', label = 'WM')\n",
    "ax.scatter(X2[:,0], X2[:,1], c = 'k', label = 'GM')\n",
    "ax.set_xlabel('T1w intensities')\n",
    "ax.set_ylabel('T2w intensities')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "W = LDA(X, T)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "Xall= np.c_[ImgT1[mask].flatten(), ImgT2[mask].flatten()]\n",
    "Y = np.c_[np.ones((len(Xall), 1)), Xall] @ W.T"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "PosteriorProb = np.clip(np.exp(Y) / np.sum(np.exp(Y),1)[:,np.newaxis], 0, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "posteriorC1 = np.zeros(ImgT1.shape)\n",
    "posteriorC2 = np.zeros(ImgT1.shape)\n",
    "\n",
    "posteriorC1[mask] = PosteriorProb[:,0]\n",
    "posteriorC2[mask] = PosteriorProb[:,1]\n",
    "mask_WM = posteriorC1 >= 0.5\n",
    "mask_GM = posteriorC2 > 0.5"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "rgb = np.stack((posteriorC1, posteriorC2, np.zeros_like(posteriorC1)), axis = -1).astype(np.double)\n",
    "axs[0].imshow(rgb)\n",
    "axs[0].set_title('Posteriors (R-WM, G-GM)')\n",
    "axs[1].imshow(mask_WM, cmap = 'gray', interpolation = 'none')\n",
    "axs[1].set_title('WM Mask')\n",
    "axs[2].imshow(mask_GM, cmap='gray', interpolation = 'none')\n",
    "axs[2].set_title('GM Mask')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**: Can you identify where the hyper plan is placed i.e. y(x)=0? \n",
    "\n",
    "A6: Yes, all the segmented points show a clear line at their\n",
    "       interface=Hyperplane\n",
    "\n",
    "**Q7**: Is the linear hyper plane positioned as you expected or would a non-linear hyperplane perform better?\n",
    "\n",
    "A7: Yes and no - I would expect all black and green training data\n",
    "       points to be on each side of the hyperplane. Moreover the hyperplane seems\n",
    "       to be too linear and there seem to be an extras class at the low image\n",
    "       resolutions. \n",
    "\n",
    "**Q8**: Would segmentation be as good as using a single image modality using\n",
    "    thresholding?\n",
    "\n",
    "A8: If that should be the case the hyperplane would be orthogonal to one\n",
    "       of the features. It is not. So no.\n",
    "\n",
    "**Q9**: From the scatter plot does the segmentation results make sense? Are the two tissue types segmented correctly .\n",
    "\n",
    "A9: Looks good, but hard to say from a scatter plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "Xall_WM = Xall[PosteriorProb[:,0] > 0.5, :]\n",
    "Xall_GM = Xall[PosteriorProb[:,1] > 0.5, :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (10,5))\n",
    "ax.scatter(Xall_GM[:,0], Xall_GM[:,1], c = 'gray', label = 'GM')\n",
    "ax.scatter(Xall_WM[:,0], Xall_WM[:,1], c = 'greenyellow', label = 'WM')\n",
    "ax.scatter(X1[:,0], X1[:,1], c = 'g', label = 'WM Training')\n",
    "ax.scatter(X2[:,0], X2[:,1], c = 'k', label = 'GM Training')\n",
    "ax.set_xlabel('T1w intensities')\n",
    "ax.set_ylabel('T2w intensities')\n",
    "ax.set_title('Hyperplane?: C1 and C2 training samples onto all segmented voxels')\n",
    "\n",
    "plt.axis([0, 750, 0, 400])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "# Projection of the training data onto the hyperplane\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (10,5))\n",
    "ax.scatter(X1[:,0], X1[:,1], c = 'g', label = 'WM Training')\n",
    "ax.scatter(X2[:,0], X2[:,1], c = 'k', label = 'GM Training')\n",
    "W_ = W[0,1:] # The weights indicate the normal to the hyperplane, for the projection we need the perpendicular\n",
    "W_ = (W_/np.linalg.norm(W_))[::-1]\n",
    "W_[0] = -W_[0]\n",
    "for point in X1:\n",
    "  proj = np.dot(point,W_)/np.dot(W_,W_) * W_\n",
    "  ax.scatter(proj[0],proj[1],color='g')\n",
    "\n",
    "for point in X2:\n",
    "  proj = np.dot(point,W_)/np.dot(W_,W_) * W_\n",
    "  ax.scatter(proj[0],proj[1],color='k')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# W_ = W[1,1:] # The weights indicate the normal to the hyperplane, for the projection we need the perpendicular\n",
    "# W_ = (W_/np.linalg.norm(W_))[::-1]\n",
    "# W_[0] = -W_[0]\n",
    "# for point in X1:\n",
    "#   proj = np.dot(point,W_)/np.dot(W_,W_) * W_\n",
    "#   ax.scatter(proj[0],proj[1],color='r')\n",
    "\n",
    "# for point in X2:\n",
    "#   proj = np.dot(point,W_)/np.dot(W_,W_) * W_\n",
    "#   ax.scatter(proj[0],proj[1],color='b')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10**: Are the training examples representative for the segmentation results? Are you surprised that so few training examples perform so well? Do you need to be an anatomical expert to draw these?\n",
    "\n",
    "A10: Yes they are representative. Yes and no; one do not need to be an anatomical expert, but you need to understand what the method needs as input to perform well.\n",
    "\n",
    "**Q11**: Compare the segmentation results with the original image. Is the segmentation results satisfactory? Why not?\n",
    "\n",
    "A11: Yes, the WM and GM classes looks correct segmented when comparing to the anatomical structures in ImgT1 and ImgT2.\n",
    "\n",
    "**Q12**: Is one class completely wrong segmented? What is the problem?\n",
    "\n",
    "A12: Yes - If you have not masked out the backgroud voxels, all background and skull voxels also are classified as GM. Solution is to identify the background voxels and exclude these from the segmentation or to add an extra class for background/skull voxels. Also the CSF class is segmented as both GM and WM. The segmentation problem is that there are more classes in the image than the classifier has been trained to segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "tmp = np.zeros(mask_WM.shape)\n",
    "red_WM = np.stack((mask_WM, tmp, tmp), axis = -1)\n",
    "green_GM = np.stack((tmp, mask_GM, tmp), axis = -1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "def overlay_segmentation(I, M):\n",
    "    I = I/I.max()\n",
    "    I_aux, I_red = I.copy(), I.copy()\n",
    "    I_aux[M] = 0\n",
    "    I_red[M] = 1\n",
    "    tmp = np.stack((I_red, I_aux, I_aux), axis = -1)\n",
    "    return tmp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize = (15, 10))\n",
    "axs[0,0].imshow(ImgT1, cmap = 'gray')\n",
    "axs[0,0].set_title('T1w')\n",
    "axs[0,1].imshow(overlay_segmentation(ImgT1, mask_WM))\n",
    "axs[0,1].set_title('WM')\n",
    "axs[0,2].imshow(overlay_segmentation(ImgT1, mask_GM))\n",
    "axs[0,2].set_title('GM')\n",
    "\n",
    "axs[1,0].imshow(ImgT2, cmap = 'gray')\n",
    "axs[1,0].set_title('T2w')\n",
    "axs[1,1].imshow(overlay_segmentation(ImgT2, mask_WM))\n",
    "axs[1,1].set_title('WM')\n",
    "axs[1,2].imshow(overlay_segmentation(ImgT2, mask_GM))\n",
    "axs[1,2].set_title('GM')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TA_02502')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d53b8e1fd0fde6d81c38d7eb18c14552af3d2fef18d70e093d6b142056d954"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
